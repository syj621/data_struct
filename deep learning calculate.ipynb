{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import torch\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[ 0.0024, -0.0594, -0.0255, -0.0598,  0.0987, -0.1932, -0.0369, -0.1168,\n          0.0750,  0.2130],\n        [-0.1057, -0.0136, -0.0291,  0.0695,  0.0243, -0.1099, -0.0600, -0.0006,\n          0.1379,  0.0697]], grad_fn=<AddmmBackward0>)"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch import nn\n",
    "\n",
    "net=nn.Sequential(nn.Linear(20,256),\n",
    "                  nn.ReLU(),\n",
    "                  nn.Linear(256,10))\n",
    "x=torch.rand([2,20],requires_grad=True)\n",
    "net(x)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[-0.2295, -0.0390,  0.0836, -0.2754,  0.0601,  0.0010,  0.0933,  0.0803,\n          0.1384, -0.1377],\n        [-0.1802, -0.0792,  0.1049, -0.2592,  0.0502,  0.1159,  0.0770,  0.0852,\n          0.0522, -0.1805]], grad_fn=<AddmmBackward0>)"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch.nn import functional as F\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.hidden=nn.Linear(20,256)\n",
    "        self.out=nn.Linear(256,10)\n",
    "    def forward(self,X):\n",
    "        return self.out(F.relu(self.hidden(X)))\n",
    "net=MLP()\n",
    "net(x)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor(-0.0320, grad_fn=<SumBackward0>)"
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class FixMLP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.rand_weight=torch.rand([20,20],requires_grad=True)\n",
    "        self.linear=nn.Linear(20,20)\n",
    "    def forward(self,x):\n",
    "        x=self.linear(x)\n",
    "        x=F.relu(torch.mm(x,self.rand_weight)+1)\n",
    "        x=self.linear(x)\n",
    "        while x.abs().sum()>1:\n",
    "            x/=2\n",
    "        return x.sum()\n",
    "net=FixMLP()\n",
    "net(x)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[-0.0495],\n        [-0.0820]], grad_fn=<AddmmBackward0>)"
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "net = nn.Sequential(nn.Linear(4, 8), nn.ReLU(), nn.Linear(8, 1))\n",
    "X = torch.rand(size=(2, 4))\n",
    "net(X)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict([('weight', tensor([[-0.1971,  0.1875,  0.3057, -0.3244, -0.1922,  0.1017,  0.2911, -0.3439]])), ('bias', tensor([-0.2181]))])\n"
     ]
    }
   ],
   "source": [
    "print(net[2].state_dict())"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.nn.parameter.Parameter'>\n",
      "Parameter containing:\n",
      "tensor([-0.2181], requires_grad=True)\n",
      "tensor([-0.2181])\n"
     ]
    }
   ],
   "source": [
    "print(type(net[2].bias))\n",
    "print(net[2].bias)\n",
    "print(net[2].bias.data)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('0.weight', Parameter containing:\n",
      "tensor([[-0.1515, -0.2626,  0.3383,  0.4945],\n",
      "        [ 0.4485, -0.2808, -0.0754,  0.3334],\n",
      "        [ 0.2859,  0.3076,  0.0753,  0.1680],\n",
      "        [-0.4506, -0.4266,  0.4324, -0.4394],\n",
      "        [-0.1500, -0.1373, -0.0658, -0.3953],\n",
      "        [ 0.1940,  0.1810,  0.0532,  0.4866],\n",
      "        [-0.3189, -0.3646,  0.3632,  0.0605],\n",
      "        [-0.0617,  0.0129, -0.4018,  0.0296]], requires_grad=True)), ('0.bias', Parameter containing:\n",
      "tensor([-0.0048,  0.1358, -0.1158, -0.2165,  0.0749, -0.3402, -0.4369,  0.2469],\n",
      "       requires_grad=True)), ('2.weight', Parameter containing:\n",
      "tensor([[-0.1971,  0.1875,  0.3057, -0.3244, -0.1922,  0.1017,  0.2911, -0.3439]],\n",
      "       requires_grad=True)), ('2.bias', Parameter containing:\n",
      "tensor([-0.2181], requires_grad=True))]\n"
     ]
    }
   ],
   "source": [
    "print([(i,k) for i,k in net.named_parameters()])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[0.2745]], grad_fn=<AddmmBackward0>)"
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "share=nn.Linear(8,8)\n",
    "net=nn.Sequential(nn.Linear(4,8),nn.ReLU(),\n",
    "                  share,nn.ReLU(),\n",
    "                  share,nn.ReLU(),\n",
    "                  nn.Linear(8,1))\n",
    "x=torch.rand(1,4)\n",
    "net(x)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed Mar 15 20:52:56 2023       \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 531.18                 Driver Version: 531.18       CUDA Version: 12.1     |\n",
      "|-----------------------------------------+----------------------+----------------------+\n",
      "| GPU  Name                      TCC/WDDM | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf            Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                      |               MIG M. |\n",
      "|=========================================+======================+======================|\n",
      "|   0  NVIDIA GeForce RTX 3090 Ti    WDDM | 00000000:01:00.0  On |                  Off |\n",
      "|  0%   40C    P8               27W / 450W|   1747MiB / 24564MiB |     14%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "                                                                                         \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                            |\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
      "|        ID   ID                                                             Usage      |\n",
      "|=======================================================================================|\n",
      "|    0   N/A  N/A      5440    C+G   ....0_x64__kzh8wxbdkxb8p\\DCv2\\DCv2.exe    N/A      |\n",
      "|    0   N/A  N/A      5720    C+G   ...6.0_x64__cv1g1gvanyjgm\\WhatsApp.exe    N/A      |\n",
      "|    0   N/A  N/A      6800    C+G   ...GeForce Experience\\NVIDIA Share.exe    N/A      |\n",
      "|    0   N/A  N/A      7848    C+G   C:\\Windows\\System32\\dwm.exe               N/A      |\n",
      "|    0   N/A  N/A      9824    C+G   C:\\Windows\\explorer.exe                   N/A      |\n",
      "|    0   N/A  N/A      9980    C+G   ...nt.CBS_cw5n1h2txyewy\\SearchHost.exe    N/A      |\n",
      "|    0   N/A  N/A     10124    C+G   ...on\\110.0.1587.69\\msedgewebview2.exe    N/A      |\n",
      "|    0   N/A  N/A     10284    C+G   ...on\\wallpaper_engine\\wallpaper32.exe    N/A      |\n",
      "|    0   N/A  N/A     11192    C+G   ...crosoft\\Edge\\Application\\msedge.exe    N/A      |\n",
      "|    0   N/A  N/A     12364    C+G   ...GeForce Experience\\NVIDIA Share.exe    N/A      |\n",
      "|    0   N/A  N/A     12704    C+G   ...\\Huorong\\Sysdiag\\bin\\HipsDaemon.exe    N/A      |\n",
      "|    0   N/A  N/A     13100    C+G   ...of Legends\\LeagueClientUxRender.exe    N/A      |\n",
      "|    0   N/A  N/A     13480    C+G   ...\\cef\\cef.win7x64\\steamwebhelper.exe    N/A      |\n",
      "|    0   N/A  N/A     13508    C+G   ...siveControlPanel\\SystemSettings.exe    N/A      |\n",
      "|    0   N/A  N/A     14360    C+G   ...Data\\Local\\Programs\\OP.GG\\OP.GG.exe    N/A      |\n",
      "|    0   N/A  N/A     15740    C+G   ... Center\\Mystic Light\\LEDKeeper2.exe    N/A      |\n",
      "|    0   N/A  N/A     16424    C+G   ...2txyewy\\StartMenuExperienceHost.exe    N/A      |\n",
      "|    0   N/A  N/A     16460    C+G   ...CBS_cw5n1h2txyewy\\TextInputHost.exe    N/A      |\n",
      "|    0   N/A  N/A     17444    C+G   ...les\\microsoft shared\\ink\\TabTip.exe    N/A      |\n",
      "|    0   N/A  N/A     20424    C+G   ...71.0_x64__8wekyb3d8bbwe\\GameBar.exe    N/A      |\n",
      "+---------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "outputs": [
    {
     "data": {
      "text/plain": "device(type='cuda', index=1)"
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.device('cuda:1')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "outputs": [
    {
     "data": {
      "text/plain": "1"
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.device_count()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "outputs": [
    {
     "data": {
      "text/plain": "device(type='cuda', index=0)"
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x=torch.rand(1,5,device='cuda')\n",
    "x.device"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[0.4219]], device='cuda:0', grad_fn=<AddmmBackward0>)"
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net=nn.Sequential(nn.Linear(5,1))\n",
    "net.to(device='cuda')\n",
    "net(x)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
